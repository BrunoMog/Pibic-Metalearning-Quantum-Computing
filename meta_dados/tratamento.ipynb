{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54be9577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4b68e",
   "metadata": {},
   "source": [
    "### VISUALIZANDO O DATASET FORNECIDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa76c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Ansatz_supervised_training_reports(CostaSH).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8603efd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARQUITETURA_ANSATZ</th>\n",
       "      <th>INPUT_EMBEDDING</th>\n",
       "      <th>DATASET</th>\n",
       "      <th>DATASET_DIVISION_INDEX</th>\n",
       "      <th>OPTIMIZER</th>\n",
       "      <th>UNSUPERVISED_METRIC</th>\n",
       "      <th>MEASURED_WIRES</th>\n",
       "      <th>MEASURE_TYPE</th>\n",
       "      <th>TRAIN_METRIC_COST</th>\n",
       "      <th>TEST_METRIC_COST</th>\n",
       "      <th>TRAIN_ACCURACY</th>\n",
       "      <th>TEST_ACCURACY</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>BIAS</th>\n",
       "      <th>USE_BIAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ry</td>\n",
       "      <td>amplitude</td>\n",
       "      <td>xor_50samples_no_noise</td>\n",
       "      <td>0</td>\n",
       "      <td>SPSAOptimizer(10)</td>\n",
       "      <td>supervised</td>\n",
       "      <td>1</td>\n",
       "      <td>expval</td>\n",
       "      <td>0.302347</td>\n",
       "      <td>0.377357</td>\n",
       "      <td>0.075087</td>\n",
       "      <td>-0.025316</td>\n",
       "      <td>[0.53625616]</td>\n",
       "      <td>[0.10402457]</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ry</td>\n",
       "      <td>amplitude</td>\n",
       "      <td>xor_50samples_no_noise</td>\n",
       "      <td>0</td>\n",
       "      <td>GradientDescentOptimizer(1)</td>\n",
       "      <td>supervised</td>\n",
       "      <td>1</td>\n",
       "      <td>expval</td>\n",
       "      <td>0.143496</td>\n",
       "      <td>0.132293</td>\n",
       "      <td>0.625850</td>\n",
       "      <td>0.637273</td>\n",
       "      <td>[1.67174535]</td>\n",
       "      <td>[0.64652642]</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ry</td>\n",
       "      <td>amplitude</td>\n",
       "      <td>xor_50samples_no_noise</td>\n",
       "      <td>0</td>\n",
       "      <td>NesterovMomentumOptimizer(0.1)</td>\n",
       "      <td>supervised</td>\n",
       "      <td>1</td>\n",
       "      <td>expval</td>\n",
       "      <td>0.143032</td>\n",
       "      <td>0.135463</td>\n",
       "      <td>0.693814</td>\n",
       "      <td>0.809091</td>\n",
       "      <td>[1.60658165]</td>\n",
       "      <td>[0.60539028]</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ry</td>\n",
       "      <td>amplitude</td>\n",
       "      <td>xor_50samples_no_noise</td>\n",
       "      <td>1</td>\n",
       "      <td>SPSAOptimizer(10)</td>\n",
       "      <td>supervised</td>\n",
       "      <td>1</td>\n",
       "      <td>expval</td>\n",
       "      <td>0.288678</td>\n",
       "      <td>0.322704</td>\n",
       "      <td>0.103410</td>\n",
       "      <td>0.069620</td>\n",
       "      <td>[0.52921011]</td>\n",
       "      <td>[0.12613722]</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ry</td>\n",
       "      <td>amplitude</td>\n",
       "      <td>xor_50samples_no_noise</td>\n",
       "      <td>1</td>\n",
       "      <td>GradientDescentOptimizer(1)</td>\n",
       "      <td>supervised</td>\n",
       "      <td>1</td>\n",
       "      <td>expval</td>\n",
       "      <td>0.130292</td>\n",
       "      <td>0.171823</td>\n",
       "      <td>0.765306</td>\n",
       "      <td>0.350909</td>\n",
       "      <td>[1.57184023]</td>\n",
       "      <td>[0.67975578]</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ARQUITETURA_ANSATZ INPUT_EMBEDDING                 DATASET  \\\n",
       "0                 ry       amplitude  xor_50samples_no_noise   \n",
       "1                 ry       amplitude  xor_50samples_no_noise   \n",
       "2                 ry       amplitude  xor_50samples_no_noise   \n",
       "3                 ry       amplitude  xor_50samples_no_noise   \n",
       "4                 ry       amplitude  xor_50samples_no_noise   \n",
       "\n",
       "   DATASET_DIVISION_INDEX                       OPTIMIZER UNSUPERVISED_METRIC  \\\n",
       "0                       0               SPSAOptimizer(10)          supervised   \n",
       "1                       0     GradientDescentOptimizer(1)          supervised   \n",
       "2                       0  NesterovMomentumOptimizer(0.1)          supervised   \n",
       "3                       1               SPSAOptimizer(10)          supervised   \n",
       "4                       1     GradientDescentOptimizer(1)          supervised   \n",
       "\n",
       "   MEASURED_WIRES MEASURE_TYPE  TRAIN_METRIC_COST  TEST_METRIC_COST  \\\n",
       "0               1       expval           0.302347          0.377357   \n",
       "1               1       expval           0.143496          0.132293   \n",
       "2               1       expval           0.143032          0.135463   \n",
       "3               1       expval           0.288678          0.322704   \n",
       "4               1       expval           0.130292          0.171823   \n",
       "\n",
       "   TRAIN_ACCURACY  TEST_ACCURACY        WEIGHT          BIAS USE_BIAS  \n",
       "0        0.075087      -0.025316  [0.53625616]  [0.10402457]      YES  \n",
       "1        0.625850       0.637273  [1.67174535]  [0.64652642]      YES  \n",
       "2        0.693814       0.809091  [1.60658165]  [0.60539028]      YES  \n",
       "3        0.103410       0.069620  [0.52921011]  [0.12613722]      YES  \n",
       "4        0.765306       0.350909  [1.57184023]  [0.67975578]      YES  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2afc428a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores únicos em ARQUITETURA_ANSATZ:\n",
      "['ry' 'rx' 'rz' 'ru' 'hr' 'ruu' '4_wana' '8_nake' '9_divwe' '1_mochi'\n",
      " '5_tano' '7_sambwadi' 'E' 'B' 'H' 'phi' 'beta' 'G' 'A' 'C' 'D' 'M' 'K'\n",
      " 'F' 'J' 'I' 'N' 'O' 'L' 'gamma' 'theta' 'alpha' '0_zero' '3_tatu'\n",
      " '2_yadi' '6_samanu']\n",
      "Número de valores únicos: 36\n",
      "\n",
      "Valores únicos em INPUT_EMBEDDING:\n",
      "['amplitude' 'phasex' 'phasey']\n",
      "Número de valores únicos: 3\n",
      "\n",
      "Valores únicos em DATASET:\n",
      "['xor_50samples_no_noise' 'xor_500samples_low_noise'\n",
      " 'xor_500samples_no_noise' 'xor_50samples_low_noise'\n",
      " 'circles_500samples_low_noise' 'circles_500samples_no_noise'\n",
      " 'circles_50samples_low_noise' 'circles_50samples_no_noise'\n",
      " 'moons_500samples_low_noise' 'moons_500samples_no_noise'\n",
      " 'moons_50samples_no_noise' 'moons_50samples_low_noise'\n",
      " 'blobs_2classes_2features_50samples_low_noise'\n",
      " 'blobs_2classes_2features_500samples_low_noise'\n",
      " 'blobs_2classes_2features_50samples_no_noise'\n",
      " 'blobs_2classes_2features_500samples_no_noise'\n",
      " 'blobs_3classes_2features_50samples_low_noise'\n",
      " 'blobs_3classes_2features_50samples_no_noise'\n",
      " 'blobs_3classes_2features_500samples_low_noise'\n",
      " 'blobs_3classes_2features_500samples_no_noise'\n",
      " 'blobs_4classes_2features_50samples_no_noise'\n",
      " 'blobs_4classes_2features_500samples_no_noise'\n",
      " 'blobs_4classes_2features_50samples_low_noise'\n",
      " 'blobs_4classes_2features_500samples_low_noise'\n",
      " 'blobs_3classes_8features_50samples_low_noise'\n",
      " 'blobs_3classes_8features_500samples_no_noise'\n",
      " 'blobs_3classes_8features_500samples_low_noise'\n",
      " 'blobs_3classes_8features_50samples_no_noise'\n",
      " 'blobs_2classes_8features_500samples_no_noise'\n",
      " 'blobs_2classes_8features_50samples_no_noise'\n",
      " 'blobs_2classes_8features_50samples_low_noise'\n",
      " 'blobs_2classes_8features_500samples_low_noise'\n",
      " 'blobs_4classes_8features_50samples_no_noise'\n",
      " 'blobs_4classes_8features_50samples_low_noise'\n",
      " 'blobs_4classes_8features_500samples_no_noise'\n",
      " 'blobs_4classes_8features_500samples_low_noise'\n",
      " 'blobs_2classes_16features_50samples_no_noise'\n",
      " 'blobs_2classes_16features_50samples_low_noise'\n",
      " 'blobs_2classes_16features_500samples_low_noise'\n",
      " 'blobs_2classes_16features_500samples_no_noise'\n",
      " 'blobs_4classes_16features_500samples_no_noise'\n",
      " 'blobs_4classes_16features_50samples_low_noise'\n",
      " 'blobs_4classes_16features_50samples_no_noise'\n",
      " 'blobs_4classes_16features_500samples_low_noise'\n",
      " 'blobs_3classes_16features_50samples_low_noise'\n",
      " 'blobs_3classes_16features_50samples_no_noise'\n",
      " 'blobs_3classes_16features_500samples_no_noise'\n",
      " 'blobs_3classes_16features_500samples_low_noise'\n",
      " 'blobs_2classes_4features_50samples_no_noise'\n",
      " 'blobs_2classes_4features_500samples_no_noise'\n",
      " 'blobs_2classes_4features_500samples_low_noise'\n",
      " 'blobs_2classes_4features_50samples_low_noise'\n",
      " 'blobs_4classes_4features_50samples_low_noise'\n",
      " 'blobs_4classes_4features_500samples_low_noise'\n",
      " 'blobs_4classes_4features_500samples_no_noise'\n",
      " 'blobs_4classes_4features_50samples_no_noise'\n",
      " 'blobs_3classes_4features_50samples_no_noise'\n",
      " 'blobs_3classes_4features_50samples_low_noise'\n",
      " 'blobs_3classes_4features_500samples_no_noise'\n",
      " 'blobs_3classes_4features_500samples_low_noise']\n",
      "Número de valores únicos: 60\n",
      "\n",
      "Valores únicos em DATASET_DIVISION_INDEX:\n",
      "[0 1 2 3 4]\n",
      "Número de valores únicos: 5\n",
      "\n",
      "Valores únicos em OPTIMIZER:\n",
      "['SPSAOptimizer(10)' 'GradientDescentOptimizer(1)'\n",
      " 'NesterovMomentumOptimizer(0.1)']\n",
      "Número de valores únicos: 3\n",
      "\n",
      "Valores únicos em UNSUPERVISED_METRIC:\n",
      "['supervised']\n",
      "Número de valores únicos: 1\n",
      "\n",
      "Valores únicos em MEASURED_WIRES:\n",
      "[1]\n",
      "Número de valores únicos: 1\n",
      "\n",
      "Valores únicos em MEASURE_TYPE:\n",
      "['expval']\n",
      "Número de valores únicos: 1\n",
      "\n",
      "Valores únicos em TRAIN_METRIC_COST:\n",
      "[ 0.30234727  0.14349634  0.14303181 ...  0.46256053 51.06432131\n",
      "  0.2882964 ]\n",
      "Número de valores únicos: 33409\n",
      "\n",
      "Valores únicos em TEST_METRIC_COST:\n",
      "[ 0.37735683  0.13229328  0.13546272 ...  0.47637942 51.28227383\n",
      "  0.2514567 ]\n",
      "Número de valores únicos: 33404\n",
      "\n",
      "Valores únicos em TRAIN_ACCURACY:\n",
      "[0.07508675 0.62585034 0.69381379 ... 0.30896103 0.42665551 0.42392646]\n",
      "Número de valores únicos: 12187\n",
      "\n",
      "Valores únicos em TEST_ACCURACY:\n",
      "[-0.02531646  0.63727273  0.80909091 ...  0.36896731  0.44937656\n",
      "  0.20668524]\n",
      "Número de valores únicos: 8289\n",
      "\n",
      "Valores únicos em WEIGHT:\n",
      "['[0.53625616]' '[1.67174535]' '[1.60658165]' ...\n",
      " '[-0.12028051  1.51525632 -0.79930083 -0.81829326  1.06320066  1.31049225\\n -0.4731261  -1.46504916 -1.4646482  -0.18565089 -0.65961151  1.50139431]'\n",
      " '[-12.17208898   0.112668    -0.87978253   1.84341721  -6.0553695\\n  -0.05268104  -0.66268114  -2.21999611  -1.95213237 -15.93375188\\n  -0.5965667    1.33860108]'\n",
      " '[-0.69758912  1.4359499  -0.87978253 -1.09308601  0.03443284  1.08025041\\n -0.32962334 -1.62658897 -1.23699857  0.01369776 -0.5965667   1.33860108]']\n",
      "Número de valores únicos: 33175\n",
      "\n",
      "Valores únicos em BIAS:\n",
      "['[0.10402457]' '[0.64652642]' '[0.60539028]' ... '[-0.40796107]'\n",
      " '[6.79073054]' '[-0.50417649]']\n",
      "Número de valores únicos: 33301\n",
      "\n",
      "Valores únicos em USE_BIAS:\n",
      "['YES']\n",
      "Número de valores únicos: 1\n"
     ]
    }
   ],
   "source": [
    "# Valores únicos de todas as colunas\n",
    "valores_unicos = {col: df[col].unique() for col in df.columns}\n",
    "\n",
    "# Exibindo os resultados\n",
    "for col, valores in valores_unicos.items():\n",
    "    print(f\"\\nValores únicos em {col}:\")\n",
    "    print(valores)\n",
    "    print(f\"Número de valores únicos: {len(valores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b480706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordenando o DataFrame por 'ARQUITETURA_ANSATZ'\n",
    "df_sorted = df.sort_values(by=['ARQUITETURA_ANSATZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9fe1c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores únicos de 'ARQUITETURA_ANSATZ' após ordenação:\n",
      "['0_zero' '1_mochi' '2_yadi' '3_tatu' '4_wana' '5_tano' '6_samanu'\n",
      " '7_sambwadi' '8_nake' '9_divwe' 'A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J'\n",
      " 'K' 'L' 'M' 'N' 'O' 'alpha' 'beta' 'gamma' 'hr' 'phi' 'ru' 'ruu' 'rx'\n",
      " 'ry' 'rz' 'theta']\n",
      "Número de valores únicos após ordenação: 36\n"
     ]
    }
   ],
   "source": [
    "# verificando a ordem dos valores únicos de 'ARQUITETURA_ANSATZ' após a ordenação\n",
    "valores_unicos_sorted = df_sorted['ARQUITETURA_ANSATZ'].unique()\n",
    "print(\"\\nValores únicos de 'ARQUITETURA_ANSATZ' após ordenação:\")\n",
    "print(valores_unicos_sorted)\n",
    "print(f\"Número de valores únicos após ordenação: {len(valores_unicos_sorted)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c416af73",
   "metadata": {},
   "source": [
    "### TRANSFORMANDO O DATASET PARA O INPUT DOS MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ba358b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformar_dataframe(df, file_path, file_metrics = \"./../datasets/metrics/\",  target=\"ACURACIA_TESTE\"):\n",
    "\n",
    "    \"\"\"\n",
    "    Função para transformar os metadados do treinamento do ansatz nos dados para os modelos clássicos.\n",
    "    Parâmetros: df: DataFrame com os metadados do treinamento do ansatz\n",
    "              file_metrics: caminho do arquivo com os metadados do treinamento do ansatz\n",
    "              file_path: caminho para salvar o arquivo csv\n",
    "              target: nome da coluna alvo (default: \"ACURACIA_TESTE\")\n",
    "    Retorna: Arquivos csv com os dados transformados\n",
    "    \"\"\"\n",
    "    # ordenando o DataFrame por 'ARQUITETURA_ANSATZ'\n",
    "    df = df.sort_values(by=['ARQUITETURA_ANSATZ'])\n",
    "\n",
    "    # mapeamento dos valores únicos de 'ARQUITETURA_ANSATZ' para números\n",
    "    ansatz_mapping = {val: i for i, val in enumerate(df['ARQUITETURA_ANSATZ'].unique())}\n",
    "\n",
    "    # mapeamento do valores únicos de 'INPUT_EMBEDDING' para números\n",
    "    embedding_mapping = {val: i for i, val in enumerate(df['INPUT_EMBEDDING'].unique())}\n",
    "\n",
    "    # mapeamento do valores únicos de 'T' para números\n",
    "    unsupervised_mapping = {val: i for i, val in enumerate(df['UNSUPERVISED_METRIC'].unique())}\n",
    "\n",
    "    #mapeamento do valores únicos de 'OPTIMIZER' para números\n",
    "    optimizer_mapping = {val: i for i, val in enumerate(df['OPTIMIZER'].unique())}\n",
    "\n",
    "    # exibindo os mapeamentos\n",
    "    print(\"\\nMapeamento de 'ARQUITETURA_ANSATZ' para números:\")\n",
    "    for val, i in ansatz_mapping.items():\n",
    "        print(f\"{val}: {i}\")\n",
    "    print(\"\\nMapeamento de 'INPUT_EMBEDDING' para números:\")\n",
    "    for val, i in embedding_mapping.items():\n",
    "        print(f\"{val}: {i}\")\n",
    "    print(\"\\nMapeamento de 'UNSUPERVISED_METRIC' para números:\")\n",
    "    for val, i in unsupervised_mapping.items():\n",
    "        print(f\"{val}: {i}\")\n",
    "    print(\"\\nMapeamento de 'OPTIMIZER' para números:\")\n",
    "    for val, i in optimizer_mapping.items():\n",
    "        print(f\"{val}: {i}\")\n",
    "\n",
    "\n",
    "    # nomes dos datasets\n",
    "    datasets = df['DATASET'].unique()\n",
    "\n",
    "    # Criando uma lista para armazenar as métricas  \n",
    "    metrics = []\n",
    "\n",
    "    for dataset in datasets:\n",
    "        # Carregando as métricas\n",
    "        with open(file_metrics + dataset + \".pkl\", 'rb') as file:\n",
    "            aux_metrics = pickle.load(file)\n",
    "        # Adicionando as métricas à lista\n",
    "        metrics.append(aux_metrics)\n",
    "\n",
    "    new_df = {\n",
    "        'f1': [],\n",
    "        'f1v': [], \n",
    "        'f2': [], \n",
    "        'f3': [], \n",
    "        'f4': [], \n",
    "        'l1': [], \n",
    "        'l2': [], \n",
    "        'l3': [], \n",
    "        'n1': [], \n",
    "        'n2': [], \n",
    "        'n3': [], \n",
    "        'n4': [], \n",
    "        't1': [], \n",
    "        'lsc': [], \n",
    "        'density': [], \n",
    "        'clsCoef': [], \n",
    "        'hubs': [], \n",
    "        't2': [], \n",
    "        't3': [], \n",
    "        't4': [], \n",
    "        'c1': [], \n",
    "        'c2': [],\n",
    "        'target': []\n",
    "    }\n",
    "\n",
    "\n",
    "    for sample_id in range(5):\n",
    "\n",
    "        #filtrar pelo número da sample\n",
    "        df_sample = df[df[\"DATASET_DIVISION_INDEX\"]==sample_id]\n",
    "\n",
    "        df_best_accuracy = copy.deepcopy(new_df)\n",
    "        df_best_ansatz = copy.deepcopy(new_df)\n",
    "        df_unsupervised_metric = copy.deepcopy(new_df)\n",
    "        df_best_embedding = copy.deepcopy(new_df)\n",
    "        df_best_optimizer = copy.deepcopy(new_df)\n",
    "\n",
    "        for metric in metrics:\n",
    "\n",
    "            #filtrar pelo nome do arquivo\n",
    "            df_arq_sample = df_sample[df_sample[\"DATASET\"]==metric[\"arquivo\"]]\n",
    "\n",
    "            #filtrar pelo Bias\n",
    "            df_arq_sample_bias = df_arq_sample[df_arq_sample[\"USE_BIAS\"]==\"YES\"]\n",
    "\n",
    "            #preencher os dataframes\n",
    "            for key in new_df.keys():\n",
    "\n",
    "                if key != 'target':\n",
    "\n",
    "                    df_best_accuracy[key].append(metric[key][sample_id])\n",
    "                    df_best_ansatz[key].append(metric[key][sample_id])\n",
    "                    df_unsupervised_metric[key].append(metric[key][sample_id])\n",
    "                    df_best_embedding[key].append(metric[key][sample_id])\n",
    "                    df_best_optimizer[key].append(metric[key][sample_id])\n",
    "\n",
    "                else:\n",
    "                    #preencher a coluna target\n",
    "\n",
    "                    idx = df_arq_sample_bias[target].idxmax()\n",
    "\n",
    "                    # para a melhor acurácia\n",
    "                    df_best_accuracy[key].append(df_arq_sample_bias.loc[idx, target])\n",
    "\n",
    "                    # para o melhor ansatz\n",
    "                    df_best_ansatz[key].append(ansatz_mapping[df_arq_sample_bias.loc[idx, 'ARQUITETURA_ANSATZ']])\n",
    "\n",
    "                    # para a melhor métrica não supervisionada\n",
    "                    df_unsupervised_metric[key].append(unsupervised_mapping[df_arq_sample_bias.loc[idx, 'UNSUPERVISED_METRIC']])\n",
    "\n",
    "                    # para o melhor embedding\n",
    "                    df_best_embedding[key].append(embedding_mapping[df_arq_sample_bias.loc[idx, 'INPUT_EMBEDDING']])\n",
    "\n",
    "                    # para o melhor optimizer\n",
    "                    df_best_optimizer[key].append(optimizer_mapping[df_arq_sample_bias.loc[idx, 'OPTIMIZER']])\n",
    "\n",
    "        # criar o caminho para salvar os arquivos\n",
    "        file_path_ = f\"{file_path}/input_data/experiment_{sample_id}/\"\n",
    "        if not os.path.exists(file_path_):\n",
    "            os.makedirs(file_path_)\n",
    "\n",
    "        # salvar os dicionários em arquivos csv\n",
    "        df_best_accuracy = pd.DataFrame(df_best_accuracy)\n",
    "        df_best_accuracy.to_csv(file_path_ + \"best_accuracy_sample_\" + str(sample_id) + \".csv\", index=False)\n",
    "\n",
    "        df_best_ansatz = pd.DataFrame(df_best_ansatz)\n",
    "        df_best_ansatz.to_csv(file_path_ + \"best_ansatz_sample_\" + str(sample_id) + \".csv\", index=False)\n",
    "\n",
    "        df_unsupervised_metric = pd.DataFrame(df_unsupervised_metric)\n",
    "        df_unsupervised_metric.to_csv(file_path_ + \"unsupervised_metric_sample_\" + str(sample_id) + \".csv\", index=False)\n",
    "\n",
    "        df_best_embedding = pd.DataFrame(df_best_embedding)\n",
    "        df_best_embedding.to_csv(file_path_ + \"best_embedding_sample_\" + str(sample_id) + \".csv\", index=False)\n",
    "\n",
    "        df_best_optimizer = pd.DataFrame(df_best_optimizer)\n",
    "        df_best_optimizer.to_csv(file_path_ + \"best_optimizer_sample_\" + str(sample_id) + \".csv\", index=False)\n",
    "\n",
    "    # salvando os mapeamentos em arquivos pickle\n",
    "    with open(file_path + \"input_data/ansatz_mapping.pkl\", 'wb') as file:\n",
    "        pickle.dump(ansatz_mapping, file)\n",
    "    with open(file_path + \"input_data/embedding_mapping.pkl\", 'wb') as file:\n",
    "        pickle.dump(embedding_mapping, file)\n",
    "    with open(file_path + \"input_data/unsupervised_mapping.pkl\", 'wb') as file:\n",
    "        pickle.dump(unsupervised_mapping, file)\n",
    "    with open(file_path + \"input_data/optimizer_mapping.pkl\", 'wb') as file:\n",
    "        pickle.dump(optimizer_mapping, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5054f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mapeamento de 'ARQUITETURA_ANSATZ' para números:\n",
      "0_zero: 0\n",
      "1_mochi: 1\n",
      "2_yadi: 2\n",
      "3_tatu: 3\n",
      "4_wana: 4\n",
      "5_tano: 5\n",
      "6_samanu: 6\n",
      "7_sambwadi: 7\n",
      "8_nake: 8\n",
      "9_divwe: 9\n",
      "A: 10\n",
      "B: 11\n",
      "C: 12\n",
      "D: 13\n",
      "E: 14\n",
      "F: 15\n",
      "G: 16\n",
      "H: 17\n",
      "I: 18\n",
      "J: 19\n",
      "K: 20\n",
      "L: 21\n",
      "M: 22\n",
      "N: 23\n",
      "O: 24\n",
      "alpha: 25\n",
      "beta: 26\n",
      "gamma: 27\n",
      "hr: 28\n",
      "phi: 29\n",
      "ru: 30\n",
      "ruu: 31\n",
      "rx: 32\n",
      "ry: 33\n",
      "rz: 34\n",
      "theta: 35\n",
      "\n",
      "Mapeamento de 'INPUT_EMBEDDING' para números:\n",
      "phasex: 0\n",
      "phasey: 1\n",
      "amplitude: 2\n",
      "\n",
      "Mapeamento de 'UNSUPERVISED_METRIC' para números:\n",
      "supervised: 0\n",
      "\n",
      "Mapeamento de 'OPTIMIZER' para números:\n",
      "SPSAOptimizer(10): 0\n",
      "GradientDescentOptimizer(1): 1\n",
      "NesterovMomentumOptimizer(0.1): 2\n"
     ]
    }
   ],
   "source": [
    "transformar_dataframe(df=df_sorted, file_path=\"./\", target=\"TEST_ACCURACY\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
